{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4995de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.graph.python import max_flow\n",
    "from ortools.sat.python import cp_model\n",
    "from ortools.linear_solver import pywraplp\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cff3208",
   "metadata": {},
   "source": [
    "# Paper Reviewer Assignment\n",
    "## Problem Description\n",
    "The chair of a conference must assign scientific papers to reviewers in a balance way. There are $N$ papers $1, 2, …, N$ and $M$ reviewers $1, 2, …, M$. \n",
    "\n",
    "- Each paper i has a list $L(i)$ of reviewers who are willing to review that paper. A review plan is an assignment reviewers to papers. The load of a reviewer is the number of papers he/she have to review. Given a constant b, compute the assignment such that:\n",
    "\n",
    "- Each paper is reviewed by exactly b reviewers \n",
    "\n",
    "The maximum load of all reviewers is minimal\n",
    "In the solution, each paper i is represented by a list $r(i, 1), r(i, 2), . . ., r(i, b)$ of b reviewers asssigned to this paper\n",
    "## Model Formulation\n",
    "### Set and Indices\n",
    "$Papers=\\{i : i \\in (1,2,3,...,N)\\}$: Set of Papers\n",
    "\n",
    "$Reviewers=\\{ j: j \\in (1,2,3,...,M)\\}$: Set of Reviewers\n",
    "\n",
    "$Pairings=\\{(i,j) \\in Papers \\times Reviewers \\}$: Set of all possible paper-reviewer assignments\n",
    "\n",
    "$ G=(Papers,Reviewers, Pairings)$: A bipartite graph where the set of nodes is divided into two disjoint sets: Papers and Reviewers, and Pairings represents the set of edges connecting each paper to its potential reviewers.\n",
    "\n",
    "### Parameters\n",
    "### Decision Variables\n",
    "- The variables \n",
    "$\n",
    "x_{i,j} =\n",
    "\\begin{cases}\n",
    "1 & \\text{if paper } i \\text{ is assigned by reviewer } j, \\\\\n",
    "0 & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$\n",
    "- The load of each reviewers $L(i) \\forall i \\in \\{1,2,...,n\\}$\n",
    "### Constraints \n",
    "- Each paper is reviewed by exactly $b$ reviewers\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{(i,j) \\in \\text{Pairings}}x_{i,j} = b \\quad \\forall  i \\in Papers\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "- The load of each reviewers\n",
    "\n",
    "\\begin{equation}\n",
    " L(j) = \\sum_{(i,j) \\in \\text{Pairings}} x_{i,j}  \\quad \\forall j \\in \\text{Reviewers}\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "- Get max load  \n",
    "\\begin{equation}\n",
    "M = \\max \\left( L(j) \\mid j \\in \\text{Reviewers} \\right)\n",
    "\\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "### Object function\n",
    "The maximum load of all reviewers is minimal\n",
    "\n",
    "\\begin{equation}\n",
    " \\text{Min  } M\n",
    "\\tag{0}\n",
    "\\end{equation}\n",
    "\n",
    "## Method\n",
    "- ### Mixed Intger Programing\n",
    "- ### Constraints Programing\n",
    "- ### Max Flow\n",
    "- ### Greedy\n",
    "- ### Hybrid: Greedy + Local search\n",
    "- ### Linear Programing + Randomized Rouding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb229127",
   "metadata": {},
   "source": [
    "### Reading Input Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ffcad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data():\n",
    "    with open('input.txt', 'r') as f:\n",
    "        num_papers,num_reviewers,reviews_per_paper = map(int, f.readline().strip().split())\n",
    "        willing_reviewers = {}\n",
    "        for i in range(num_papers):\n",
    "            line = list(map(int, f.readline().strip().split()))\n",
    "            paper_id = i+1\n",
    "            reviewers = line[1:]\n",
    "            willing_reviewers[paper_id] = reviewers\n",
    "    return num_papers, num_reviewers, reviews_per_paper, willing_reviewers\n",
    "def reverse_dict(willing_reviewers):\n",
    "    willing_papers = {}\n",
    "    for paper, reviewers in willing_reviewers.items():\n",
    "        for reviewer in reviewers:\n",
    "            if reviewer not in willing_papers:\n",
    "                willing_papers[reviewer] = []\n",
    "            willing_papers[reviewer].append(paper)\n",
    "    return willing_papers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd4a66",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Calculate Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b55bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_execution(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390bc4b2",
   "metadata": {},
   "source": [
    "# 1. Mixed Interger Programming Model with OR-Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ae804f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Tạo solver: MIP = Mixed Integer Programming\u001b[39;00m\n\u001b[0;32m     40\u001b[0m solver \u001b[38;5;241m=\u001b[39m pywraplp\u001b[38;5;241m.\u001b[39mSolver\u001b[38;5;241m.\u001b[39mCreateSolver(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCIP\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m \u001b[43mInterger_Programming\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m, in \u001b[0;36mtime_execution.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m      3\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 4\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      6\u001b[0m     execution_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[1;32mIn[32], line 10\u001b[0m, in \u001b[0;36mInterger_Programming\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m paper \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_papers \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m reviewer \u001b[38;5;129;01min\u001b[39;00m willing_reviewers[paper]:\n\u001b[1;32m---> 10\u001b[0m         x[(paper, reviewer)] \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mBoolVar(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx[\u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpaper\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreviewer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Ràng buộc: Mỗi paper phải được đánh giá bởi đúng số lượng reviewers\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m paper \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_papers \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@time_execution\n",
    "def Interger_Programming():\n",
    "    num_papers, num_reviewers, reviews_per_paper, willing_reviewers = input_data()  \n",
    "    solver = pywraplp.Solver.CreateSolver('SCIP')\n",
    "    \n",
    "    \n",
    "    x = {}\n",
    "    for paper in range(1, num_papers + 1):\n",
    "        for reviewer in willing_reviewers[paper]:\n",
    "            x[(paper, reviewer)] = solver.BoolVar(f'x[{paper},{reviewer}]')\n",
    "\n",
    "    # Ràng buộc: Mỗi paper phải được đánh giá bởi đúng số lượng reviewers\n",
    "    for paper in range(1, num_papers + 1):\n",
    "        solver.Add(solver.Sum(x[(paper, reviewer)] for reviewer in willing_reviewers[paper]) == reviews_per_paper)\n",
    "\n",
    "    # Ràng buộc: Tải của mỗi reviewer\n",
    "    loads = {}\n",
    "    for reviewer in range(1, num_reviewers + 1):\n",
    "        loads[reviewer] = solver.IntVar(0, num_papers, f'load[{reviewer}]')\n",
    "        solver.Add(loads[reviewer] == solver.Sum(x[(paper, reviewer)] for paper in range(1, num_papers + 1) if (paper, reviewer) in x))\n",
    "    \n",
    "    # Ràng buộc: Tải tối đa của các reviewers là nhỏ nhất\n",
    "    max_load = solver.IntVar(0, num_papers, 'max_load')\n",
    "    for reviewer in range(1, num_reviewers + 1):\n",
    "        solver.Add(loads[reviewer] <= max_load)\n",
    "\n",
    "    # Hàm mục tiêu: Tối thiểu hóa tải tối đa\n",
    "    solver.Minimize(max_load)\n",
    "\n",
    "    # Giải bài toán\n",
    "    status = solver.Solve()\n",
    "    print(f'{status}')\n",
    "    # In kết quả\n",
    "    if status == pywraplp.Solver.OPTIMAL or status == pywraplp.Solver.FEASIBLE:\n",
    "        print(max_load.solution_value())\n",
    "        \n",
    "    else:\n",
    "        print('Không tìm được nghiệm tối ưu.')\n",
    "# Tạo solver: MIP = Mixed Integer Programming\n",
    "solver = pywraplp.Solver.CreateSolver('SCIP')\n",
    "\n",
    "Interger_Programming()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca8323",
   "metadata": {},
   "source": [
    "# 2. Constraint Programming Model with OR-Tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5db3d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163.0\n",
      "Execution time: 19.8386 seconds\n"
     ]
    }
   ],
   "source": [
    "@time_execution\n",
    "def Constraint_Programming()-> None:\n",
    "    # Read input data\n",
    "    num_papers, num_reviewers, reviews_per_paper, willing_reviewers = input_data()  \n",
    "    # Create the model\n",
    "    model = cp_model.CpModel()\n",
    "    # Create binary variables for each paper-reviewer pair\n",
    "    x= {}\n",
    "    for paper in range(1, num_papers + 1):\n",
    "        for reviewer in willing_reviewers[paper]:\n",
    "            x[(paper, reviewer)] = model.NewBoolVar(f'x[{paper},{reviewer}]')\n",
    "\n",
    "    # Each paper must be reviewed by exactly reviews_per_paper reviewers\n",
    "    for paper in range(1, num_papers + 1):\n",
    "        model.Add(sum(x[(paper, reviewer)] for reviewer in willing_reviewers[paper]) == reviews_per_paper)\n",
    "    # Load for each reviewer\n",
    "    loads = {}\n",
    "    for reviewer in range(1, num_reviewers + 1):\n",
    "        loads[reviewer] = model.NewIntVar(0, num_papers, f'load[{reviewer}]')\n",
    "        model.Add(loads[reviewer] == sum(x[(paper, reviewer)] for paper in range(1, num_papers + 1) if (paper, reviewer) in x))\n",
    "    \n",
    "    # Add constraints max of loads is minium\n",
    "    max_load = model.NewIntVar(0, num_papers, 'max_load')\n",
    "    for reviewer in range(1, num_reviewers + 1):\n",
    "        model.Add(loads[reviewer] <= max_load)\n",
    "\n",
    "    # Objective: minimize the maximum load\n",
    "    model.Minimize(max_load)\n",
    "\n",
    "    # Solve the model\n",
    "    solver = cp_model.CpSolver()\n",
    "    status = solver.Solve(model)\n",
    "    # Print the solution\n",
    "    if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "        \"\"\"print(num_papers)\n",
    "        for paper in range(1, num_papers + 1):\n",
    "            print(reviews_per_paper, end=' ')\n",
    "            for reviewer in willing_reviewers[paper]:\n",
    "                if solver.Value(x[(paper, reviewer)]) == 1:\n",
    "                    print(reviewer, end=' ')\n",
    "            print()\"\"\"\n",
    "        print(solver.ObjectiveValue())\n",
    "    else:\n",
    "        print('No solution found.')\n",
    "    \n",
    "Constraint_Programming()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cfc41c",
   "metadata": {},
   "source": [
    "# 3. Max Flow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b720593",
   "metadata": {},
   "source": [
    "## Prepare Data For Directed Graph Form\n",
    "### Define the source node and sink node\n",
    "    source = 0\n",
    "    sink = num_papers + num_reviewers + 1\n",
    "### Define the arcs\n",
    "- The first type of arcs is from the source node to each paper node, with capacities equal to reviewers_per_paper\n",
    "- The second type of arcs is from each paper node to its willing reviewers, with  capacities equal 1\n",
    "- The third type of arcs is from each reviewer node to sink node, with capacities equal max of numbers papers, for each reviewer The maximum number of papers assigned to each reviewer.\n",
    "We need to transport all data from source code to sink code: $data = num \\_ papers \\times reviewers\\_ per \\_ paper$\n",
    "\n",
    "This is example visualizaion\n",
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31ff01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_data(num_papers,num_reviewers,reviews_per_paper ,willing_reviewers,max_load):\n",
    "    \n",
    "    source = 0\n",
    "    sink = num_papers + num_reviewers + 1\n",
    "\n",
    "    start_nodes = []\n",
    "    end_nodes = []\n",
    "    capacities = []\n",
    "\n",
    "    # Arcs from source to papers\n",
    "    start_nodes += [source] * num_papers\n",
    "    end_nodes += [i for i in range(1, num_papers + 1)]\n",
    "    capacities += [reviews_per_paper] * num_papers\n",
    "\n",
    "    # Arcs from papers to reviewers (with correct offset)\n",
    "    for paper in range(1, num_papers + 1):\n",
    "        for reviewer in willing_reviewers[paper]:\n",
    "            start_nodes.append(paper)\n",
    "            end_nodes.append(reviewer + num_papers)  # Add offset here\n",
    "            capacities.append(1)\n",
    "\n",
    "    # Arcs from reviewers to sink\n",
    "    for reviewer in range(1, num_reviewers + 1):\n",
    "        start_nodes.append(reviewer + num_papers)\n",
    "        end_nodes.append(sink)\n",
    "        capacities.append(max_load)\n",
    "    return start_nodes, end_nodes, capacities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38b0db2",
   "metadata": {},
   "source": [
    "## Define the solution model\n",
    "We use the graph-based solution model provided by the OR-Tools library. This model includes implementations of algorithms such as Dinic's algorithm and the Ford–Fulkerson algorithm, which can be more efficient and suitable for certain problems compared to Linear Programming or Constraint Programming approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61497532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "Execution time: 0.0420 seconds\n"
     ]
    }
   ],
   "source": [
    "@time_execution\n",
    "def max_flow_method(): \n",
    "    # Instantiate a SimpleMaxFlow solver.\n",
    "    smf = max_flow.SimpleMaxFlow()\n",
    "\n",
    "    # Read input data\n",
    "    num_papers, num_reviewers, reviews_per_paper, willing_reviewers = input_data()\n",
    "\n",
    "    #Minimum capactices of max_load\n",
    "    if (num_papers*reviews_per_paper) % num_reviewers == 0:\n",
    "        low=(num_papers*reviews_per_paper) // num_reviewers\n",
    "    else:\n",
    "        low=(num_papers*reviews_per_paper) // num_reviewers + 1\n",
    "    \n",
    "    willing_papers = reverse_dict(willing_reviewers)\n",
    "    willing_papers=dict(sorted(willing_papers.items(), key=lambda item: len(item[1])))\n",
    "    high= max(len(papers) for papers in willing_papers.values()) if willing_papers else 0\n",
    "        \n",
    "    #Dirichlet's theorem\n",
    "    max_load= low\n",
    "\n",
    "    while max_load<=high:        \n",
    "        start_nodes, end_nodes, capacities = pre_processing_data(num_papers,num_reviewers,reviews_per_paper ,willing_reviewers,max_load)\n",
    "        #   note: we could have used add_arc_with_capacity(start, end, capacity)\n",
    "        all_arcs = smf.add_arcs_with_capacity(start_nodes, end_nodes, capacities)\n",
    "\n",
    "        # Find the maximum flow between node 0 and node 4.\n",
    "        status = smf.solve(0, num_papers + num_reviewers + 1)\n",
    "\n",
    "        if (status == smf.OPTIMAL) and smf.optimal_flow()== num_papers * reviews_per_paper:\n",
    "            # Print the solution\n",
    "            \"\"\"print(num_papers)\n",
    "            solution_flows = smf.flows(all_arcs)\n",
    "            arc_indices = {arc: i for i, arc in enumerate(zip(start_nodes, end_nodes))}\n",
    "       \n",
    "            for paper in range(1, num_papers + 1):\n",
    "                print(reviews_per_paper, end=' ')\n",
    "                assigned_reviewers = []\n",
    "                \n",
    "                # Check all arcs from this paper to reviewers\n",
    "                for reviewer in willing_reviewers[paper]:\n",
    "                    arc = (paper, reviewer + num_papers)\n",
    "                    if arc in arc_indices:\n",
    "                        flow_index = arc_indices[arc]\n",
    "                        if solution_flows[flow_index] == 1:\n",
    "                            assigned_reviewers.append(reviewer)\n",
    "                \n",
    "                # Print assigned reviewers\n",
    "                for rev in assigned_reviewers[:reviews_per_paper]:  # Ensure we don't exceed required reviews\n",
    "                    print(rev, end=' ')\n",
    "                print()\"\"\"\n",
    "            print(max_load) \n",
    "            break\n",
    "        else:\n",
    "            max_load += 1\n",
    "        \n",
    "max_flow_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced8a77",
   "metadata": {},
   "source": [
    "Now we go to approximation algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186de543",
   "metadata": {},
   "source": [
    "# 4.  Greedy Algorithm\n",
    "## Greedy 1\n",
    "We prioritize willing reviewers for papers that currently have fewer assigned reviewers\n",
    "\n",
    "For each paper in sorted dictionary, We randomly choice exact __reviews_per_paper__  reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a2a691d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "Execution time: 0.0430 seconds\n"
     ]
    }
   ],
   "source": [
    "def matching_papers(num_papers, num_reviewers, reviews_per_paper, willing_reviewers):\n",
    "    load = [0] * (num_reviewers + 1)\n",
    "    sorted_dict = dict(sorted(willing_reviewers.items(), key=lambda item: len(item[1])))\n",
    "    selected_reviewers = {}\n",
    "    for paper,reviewers in sorted_dict.items():\n",
    "        #Sort the reviewers by their current load\n",
    "        reviewers.sort(key=lambda x: load[x])\n",
    "        # Select the first K reviewers\n",
    "        selected_reviewers[paper] = reviewers[:reviews_per_paper]\n",
    "        # Update the load of the selected reviewers\n",
    "        for reviewer in selected_reviewers[paper]:\n",
    "            load[reviewer] += 1\n",
    "    # Find the maximum load\n",
    "    max_load = max(load[1:])\n",
    "    return max_load, selected_reviewers\n",
    "@time_execution\n",
    "def greedy_method(): \n",
    "    # Read input data\n",
    "    num_papers, num_reviewers, reviews_per_paper, willing_reviewers = input_data()\n",
    "    \n",
    "    # Call the matching function\n",
    "    max_load, selected_reviewers = matching_papers(num_papers, num_reviewers, reviews_per_paper, willing_reviewers)\n",
    "    \n",
    "    # Print the result\n",
    "    \"\"\"print(num_papers)\n",
    "    for paper in range(1, num_papers + 1):\n",
    "        print(reviews_per_paper, end=' ')\n",
    "        for reviewer in selected_reviewers.get(paper, []):\n",
    "            print(reviewer, end=' ')\n",
    "        print()\"\"\"\n",
    "    print(max_load)\n",
    "    \n",
    "greedy_method() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c28431",
   "metadata": {},
   "source": [
    "## Greedy 2\n",
    "For each paper in the sorted dictionary, we select __reviewers_per_paper__ reviewers.\n",
    "To make the assignment more balanced, we prioritize reviewers with the minimum current load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83d12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3e8ef3d",
   "metadata": {},
   "source": [
    "# 5. Local Search \n",
    "We start with a base solution generated by a greedy algorithm, and then optimize this solution using local search.\n",
    "## Define the neighbor\n",
    "Two reviewers are considered neighbors if there exists at least one paper that both of them are willing to review.\n",
    "## Algorithm\n",
    "We select reviewer, with current load is maximum (__A__)  then for each of others, we prioritize reviewers with the minimum current load (__B__). If they are neighbors, we randomly select  __c__ in __avaiable_papers__  and swap ( reassign paper __c__ from reviewer __A__ to reviewer __B__ )\n",
    "\n",
    "This algorithm stops when there is no further change in reviewer load. We repeat the algorithm for a sufficiently large number of iterations (__times__) to allow the solution to converge.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e1ce781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max load: 163\n",
      "Execution time: 0.0780 seconds\n"
     ]
    }
   ],
   "source": [
    "def matching_papers_2(num_papers, num_reviewers, reviews_per_paper, willing_reviewers):\n",
    "    load = {i: 0 for i in range(1, num_reviewers + 1)}  # Fixed: Start from 1 instead of 0\n",
    "    sorted_dict = dict(sorted(willing_reviewers.items(), key=lambda item: len(item[1])))\n",
    "    selected_reviewers = {}\n",
    "    for paper,reviewers in sorted_dict.items():\n",
    "        #Sort the reviewers by their current load\n",
    "        reviewers.sort(key=lambda x: load[x])\n",
    "        # Select the first K reviewers\n",
    "        selected_reviewers[paper] = reviewers[:reviews_per_paper]\n",
    "        # Update the load of the selected reviewers\n",
    "        for reviewer in selected_reviewers[paper]:\n",
    "            load[reviewer] += 1\n",
    "    # Find the maximum load\n",
    "    max_load = max(load.values())\n",
    "    return max_load, selected_reviewers, load\n",
    "\n",
    "def local_search(num_papers, num_reviewers, reviews_per_paper, willing_papers, assigned_papers, current_load, times=0):\n",
    "    if times > 100:  # Limit recursion depth\n",
    "        return assigned_papers, current_load\n",
    "    \n",
    "    changed = False\n",
    "    sorted_load = dict(sorted(current_load.items(), key=lambda item: item[1]))\n",
    "    #get the max load\n",
    "    reviewer_of_max_load = max(current_load, key=current_load.get)\n",
    "    max_load = current_load[reviewer_of_max_load]\n",
    "    \n",
    "    for candidate in sorted_load.keys():\n",
    "        if sorted_load[candidate] < max_load-1:\n",
    "            # Ensure both reviewers exist in the dictionaries\n",
    "            if candidate not in willing_papers:\n",
    "                willing_papers[candidate] = []\n",
    "            if reviewer_of_max_load not in assigned_papers:\n",
    "                continue\n",
    "                \n",
    "            available_papers = list(set(willing_papers.get(candidate, [])) & set(assigned_papers[reviewer_of_max_load]))\n",
    "            if len(available_papers) > 0:\n",
    "                random_paper = random.choice(available_papers)\n",
    "                assigned_papers[candidate].append(random_paper)\n",
    "                assigned_papers[reviewer_of_max_load].remove(random_paper)\n",
    "                # Update the load\n",
    "                current_load[candidate] += 1\n",
    "                current_load[reviewer_of_max_load] -= 1\n",
    "                changed=True\n",
    "                break\n",
    "                \n",
    "    if changed:\n",
    "        return local_search(num_papers, num_reviewers, reviews_per_paper, willing_papers, assigned_papers, current_load, times+1)\n",
    "\n",
    "    return assigned_papers, current_load\n",
    "@time_execution\n",
    "def local_search_method():\n",
    "    num_papers, num_reviewers, reviews_per_paper, willing_reviewers = input_data()\n",
    "    willing_papers = reverse_dict(willing_reviewers)\n",
    "\n",
    "    \n",
    "    max_load, selected_reviewers, current_load = matching_papers_2(num_papers, num_reviewers, reviews_per_paper, willing_reviewers)\n",
    "    \n",
    "    # Calculate assigned papers for each reviewer\n",
    "    assigned_papers = reverse_dict(selected_reviewers)\n",
    "    \n",
    "    # Update willing papers by removing already assigned papers\n",
    "    reviewer_willing_papers = {}\n",
    "    for i in range(1, num_reviewers+1):\n",
    "        if i in willing_papers:\n",
    "            reviewer_willing_papers[i] = list(set(willing_papers[i]) - set(assigned_papers.get(i, [])))\n",
    "    \n",
    "    # Perform local search\n",
    "    optimized_assignments, final_load = local_search(num_papers, num_reviewers, reviews_per_paper, reviewer_willing_papers, assigned_papers, current_load)\n",
    "    selected_reviewers=reverse_dict(optimized_assignments)\n",
    "    \"\"\"print(num_papers)\n",
    "    for paper, reviewers in selected_reviewers.items():\n",
    "        print(f\"{reviews_per_paper} {' '.join(map(str, reviewers))}\")\"\"\"\n",
    "    print(f\"Max load: {max(final_load.values())}\")\n",
    "\n",
    "local_search_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf6a1e",
   "metadata": {},
   "source": [
    "# 6. Linear Programming + Randomized Rouding\n",
    "Firstly, we start with a continuous-variable solution generated by a Linear Programming model, and then convert it into a discrete-variable solution using local search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7dd79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LP Solution - Maximum load: 162.5609756097561\n",
      "164\n",
      "Execution time: 14.2064 seconds\n"
     ]
    }
   ],
   "source": [
    "@time_execution\n",
    "def main()-> None:\n",
    "    num_papers, num_reviewers, reviews_per_paper, willing_reviewers = input_data()  \n",
    "    solver=pywraplp.Solver.CreateSolver('SCIP')\n",
    "    if not solver:\n",
    "        print(\"Solver not created.\")\n",
    "        return\n",
    "    # Create binary variables for each paper-reviewer pair\n",
    "    x = {}\n",
    "    for paper in range(1, num_papers + 1):\n",
    "        for reviewer in willing_reviewers[paper]:\n",
    "            x[(paper, reviewer)] = solver.NumVar(0,1,f'x[{paper},{reviewer}]')\n",
    "    loads= {}   \n",
    "    for reviewer in range(1, num_reviewers + 1):\n",
    "        loads[reviewer] = solver.NumVar(0, num_papers, f'load[{reviewer}]')\n",
    "    for j in range(1,num_papers+1):\n",
    "        solver.Add(solver.Sum(x[(j,i)] for i in willing_reviewers[j]) == reviews_per_paper)\n",
    "    for i in range(1, num_reviewers + 1):\n",
    "        solver.Add(loads[i] == solver.Sum(x[(j, i)] for j in range(1, num_papers + 1) if (j, i) in x))\n",
    "    max_load = solver.NumVar(0, num_papers, 'max_load')\n",
    "    for i in range(1, num_reviewers + 1):\n",
    "        solver.Add(loads[i] <= max_load)\n",
    "    solver.Minimize(max_load)\n",
    "    \n",
    "    # Solve the LP model\n",
    "    status = solver.Solve()\n",
    "    \n",
    "    # Check if a solution was found\n",
    "    if status != pywraplp.Solver.OPTIMAL and status != pywraplp.Solver.FEASIBLE:\n",
    "        print('No solution found.')\n",
    "        return\n",
    "        \n",
    "    # Print the LP solution\n",
    "    print(f\"LP Solution - Maximum load: {max_load.solution_value()}\")\n",
    "    \n",
    "    # Randomized Rounding\n",
    "    assignments = {}\n",
    "    reviewer_counts = {r: 0 for r in range(1, num_reviewers + 1)}\n",
    "    \n",
    "    for paper in range(1, num_papers + 1):\n",
    "        # Get the fractional solution values for this paper\n",
    "        probabilities = []\n",
    "        reviewers = []\n",
    "        for reviewer in willing_reviewers[paper]:\n",
    "            probabilities.append(x[(paper, reviewer)].solution_value())\n",
    "            reviewers.append(reviewer)\n",
    "        \n",
    "        # Normalize probabilities (they should sum to reviews_per_paper)\n",
    "        total = sum(probabilities)\n",
    "        if total > 0:\n",
    "            probabilities = [p/total for p in probabilities]\n",
    "        # Select reviewers without replacement\n",
    "        chosen = []\n",
    "        for _ in range(reviews_per_paper):\n",
    "            if not probabilities:  # In case all probabilities are zero\n",
    "                remaining = [r for r in willing_reviewers[paper] if r not in chosen]\n",
    "                if not remaining:\n",
    "                    break\n",
    "                r = random.choice(remaining)\n",
    "            else:\n",
    "                r = random.choices(reviewers, weights=probabilities, k=1)[0]\n",
    "                while r in chosen:\n",
    "                    # Resample if we get a duplicate (for cases where we sample with replacement)\n",
    "                    r = random.choices(reviewers, weights=probabilities, k=1)[0]\n",
    "            \n",
    "            chosen.append(r)\n",
    "            reviewer_counts[r] += 1\n",
    "        \n",
    "        assignments[paper] = chosen\n",
    "    \n",
    "    # Output the results\n",
    "    print(f\"{max(reviewer_counts.values())}\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001a5a81",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b95799",
   "metadata": {},
   "source": [
    "# Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c007197d",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Approximation Algorithms: LP Relaxation, Rounding, and Randomized Rounding Techniques, My T. Thai\n",
    " Techniques https://cise.ufl.edu/~mythai/courses/2007/cis6930/Notes/Rounding.pdf\n",
    "\n",
    "[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

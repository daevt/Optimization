{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4995de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.graph.python import max_flow\n",
    "from ortools.sat.python import cp_model\n",
    "from ortools.linear_solver import pywraplp\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cff3208",
   "metadata": {},
   "source": [
    "# Paper Reviewer Assignment\n",
    "## Problem Description\n",
    "The chair of a conference must assign scientific papers to reviewers in a balance way. There are $N$ papers $1, 2, …, N$ and $M$ reviewers $1, 2, …, M$. \n",
    "\n",
    "- Each paper i has a list $L(i)$ of reviewers who are willing to review that paper. A review plan is an assignment reviewers to papers. The load of a reviewer is the number of papers he/she have to review. Given a constant b, compute the assignment such that:\n",
    "\n",
    "- Each paper is reviewed by exactly b reviewers \n",
    "\n",
    "The maximum load of all reviewers is minimal\n",
    "In the solution, each paper i is represented by a list $r(i, 1), r(i, 2), . . ., r(i, b)$ of b reviewers asssigned to this paper\n",
    "## Model Formulation\n",
    "### Set and Indices\n",
    "$Papers=\\{i : i \\in (1,2,3,...,N)\\}$: Set of Papers\n",
    "\n",
    "$Reviewers=\\{ j: j \\in (1,2,3,...,M)\\}$: Set of Reviewers\n",
    "\n",
    "$Pairings=\\{(i,j) \\in Papers \\times Reviewers \\}$: Set of all possible paper-reviewer assignments\n",
    "\n",
    "$ G=(Papers,Reviewers, Pairings)$: A bipartite graph where the set of nodes is divided into two disjoint sets: Papers and Reviewers, and Pairings represents the set of edges connecting each paper to its potential reviewers.\n",
    "\n",
    "### Parameters\n",
    "### Decision Variables\n",
    "- The variables \n",
    "$\n",
    "x_{i,j} =\n",
    "\\begin{cases}\n",
    "1 & \\text{if paper } i \\text{ is assigned by reviewer } j, \\\\\n",
    "0 & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$\n",
    "- The load of each reviewers $L(i) \\forall i \\in \\{1,2,...,n\\}$\n",
    "### Constraints \n",
    "- Each paper is reviewed by exactly $b$ reviewers\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{(i,j) \\in \\text{Pairings}}x_{i,j} = b \\quad \\forall  i \\in Papers\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "- The load of each reviewers\n",
    "\n",
    "\\begin{equation}\n",
    " L(j) = \\sum_{(i,j) \\in \\text{Pairings}} x_{i,j}  \\quad \\forall j \\in \\text{Reviewers}\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "- Get max load  \n",
    "\\begin{equation}\n",
    "M = \\max \\left( L(j) \\mid j \\in \\text{Reviewers} \\right)\n",
    "\\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "### Object function\n",
    "The maximum load of all reviewers is minimal\n",
    "\n",
    "\\begin{equation}\n",
    " \\text{Min  } M\n",
    "\\tag{0}\n",
    "\\end{equation}\n",
    "\n",
    "## Method\n",
    "- ### Mixed Intger Programing\n",
    "- ### Constraints Programing\n",
    "- ### Max Flow\n",
    "- ### Greedy\n",
    "- ### Hybrid: Greedy + Local search\n",
    "- ### Linear Programing + Randomized Rouding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb229127",
   "metadata": {},
   "source": [
    "### Reading Input Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ffcad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data():\n",
    "    with open('input.txt', 'r') as f:\n",
    "        num_papers,num_reviewers,reviews_per_paper = map(int, f.readline().strip().split())\n",
    "        willing_reviewers = {}\n",
    "        for i in range(num_papers):\n",
    "            line = list(map(int, f.readline().strip().split()))\n",
    "            paper_id = i+1\n",
    "            reviewers = line[1:]\n",
    "            willing_reviewers[paper_id] = reviewers\n",
    "    return num_papers, num_reviewers, reviews_per_paper, willing_reviewers\n",
    "def reverse_dict(willing_reviewers):\n",
    "    willing_papers = {}\n",
    "    for paper, reviewers in willing_reviewers.items():\n",
    "        for reviewer in reviewers:\n",
    "            if reviewer not in willing_papers:\n",
    "                willing_papers[reviewer] = []\n",
    "            willing_papers[reviewer].append(paper)\n",
    "    return willing_papers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd4a66",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Calculate Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b55bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_execution(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390bc4b2",
   "metadata": {},
   "source": [
    "# 1. Mixed Interger Programming Model with OR-Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae804f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time_execution\n",
    "def Interger_Programming():\n",
    "    num_papers, num_reviewers, reviews_per_paper, willing_reviewers = input_data()  \n",
    "    solver = pywraplp.Solver.CreateSolver('SCIP')\n",
    "    \n",
    "    \n",
    "    x = {}\n",
    "    for paper in range(1, num_papers + 1):\n",
    "        for reviewer in willing_reviewers[paper]:\n",
    "            x[(paper, reviewer)] = solver.BoolVar(f'x[{paper},{reviewer}]')\n",
    "\n",
    "    # Ràng buộc: Mỗi paper phải được đánh giá bởi đúng số lượng reviewers\n",
    "    for paper in range(1, num_papers + 1):\n",
    "        solver.Add(solver.Sum(x[(paper, reviewer)] for reviewer in willing_reviewers[paper]) == reviews_per_paper)\n",
    "\n",
    "    # Ràng buộc: Tải của mỗi reviewer\n",
    "    loads = {}\n",
    "    for reviewer in range(1, num_reviewers + 1):\n",
    "        loads[reviewer] = solver.IntVar(0, num_papers, f'load[{reviewer}]')\n",
    "        solver.Add(loads[reviewer] == solver.Sum(x[(paper, reviewer)] for paper in range(1, num_papers + 1) if (paper, reviewer) in x))\n",
    "    \n",
    "    # Ràng buộc: Tải tối đa của các reviewers là nhỏ nhất\n",
    "    max_load = solver.IntVar(0, num_papers, 'max_load')\n",
    "    for reviewer in range(1, num_reviewers + 1):\n",
    "        solver.Add(loads[reviewer] <= max_load)\n",
    "\n",
    "    # Hàm mục tiêu: Tối thiểu hóa tải tối đa\n",
    "    solver.Minimize(max_load)\n",
    "\n",
    "    # Giải bài toán\n",
    "    status = solver.Solve()\n",
    "    print(f'{status}')\n",
    "    # In kết quả\n",
    "    if status == pywraplp.Solver.OPTIMAL or status == pywraplp.Solver.FEASIBLE:\n",
    "        print(max_load.solution_value())\n",
    "        \n",
    "    else:\n",
    "        print('Không tìm được nghiệm tối ưu.')\n",
    "# Tạo solver: MIP = Mixed Integer Programming\n",
    "solver = pywraplp.Solver.CreateSolver('SCIP')\n",
    "\n",
    "Interger_Programming()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca8323",
   "metadata": {},
   "source": [
    "# 2. Constraint Programming Model with OR-Tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5db3d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time_execution\n",
    "def Constraint_Programming()-> None:\n",
    "    # Read input data\n",
    "    num_papers, num_reviewers, reviews_per_paper, willing_reviewers = input_data()  \n",
    "    # Create the model\n",
    "    model = cp_model.CpModel()\n",
    "    # Create binary variables for each paper-reviewer pair\n",
    "    x= {}\n",
    "    for paper in range(1, num_papers + 1):\n",
    "        for reviewer in willing_reviewers[paper]:\n",
    "            x[(paper, reviewer)] = model.NewBoolVar(f'x[{paper},{reviewer}]')\n",
    "\n",
    "    # Each paper must be reviewed by exactly reviews_per_paper reviewers\n",
    "    for paper in range(1, num_papers + 1):\n",
    "        model.Add(sum(x[(paper, reviewer)] for reviewer in willing_reviewers[paper]) == reviews_per_paper)\n",
    "    # Load for each reviewer\n",
    "    loads = {}\n",
    "    for reviewer in range(1, num_reviewers + 1):\n",
    "        loads[reviewer] = model.NewIntVar(0, num_papers, f'load[{reviewer}]')\n",
    "        model.Add(loads[reviewer] == sum(x[(paper, reviewer)] for paper in range(1, num_papers + 1) if (paper, reviewer) in x))\n",
    "    \n",
    "    # Add constraints max of loads is minium\n",
    "    max_load = model.NewIntVar(0, num_papers, 'max_load')\n",
    "    for reviewer in range(1, num_reviewers + 1):\n",
    "        model.Add(loads[reviewer] <= max_load)\n",
    "\n",
    "    # Objective: minimize the maximum load\n",
    "    model.Minimize(max_load)\n",
    "\n",
    "    # Solve the model\n",
    "    solver = cp_model.CpSolver()\n",
    "    status = solver.Solve(model)\n",
    "    # Print the solution\n",
    "    if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "        \"\"\"print(num_papers)\n",
    "        for paper in range(1, num_papers + 1):\n",
    "            print(reviews_per_paper, end=' ')\n",
    "            for reviewer in willing_reviewers[paper]:\n",
    "                if solver.Value(x[(paper, reviewer)]) == 1:\n",
    "                    print(reviewer, end=' ')\n",
    "            print()\"\"\"\n",
    "        print(solver.ObjectiveValue())\n",
    "    else:\n",
    "        print('No solution found.')\n",
    "    \n",
    "cp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cfc41c",
   "metadata": {},
   "source": [
    "# 3. Max Flow Model\n",
    "## Prepare Data For Directed Graph Form\n",
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ff01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_data(num_papers,num_reviewers,reviews_per_paper ,willing_reviewers,max_load):\n",
    "    \n",
    "    source = 0\n",
    "    sink = num_papers + num_reviewers + 1\n",
    "\n",
    "    start_nodes = []\n",
    "    end_nodes = []\n",
    "    capacities = []\n",
    "\n",
    "    # Arcs from source to papers\n",
    "    start_nodes += [source] * num_papers\n",
    "    end_nodes += [i for i in range(1, num_papers + 1)]\n",
    "    capacities += [reviews_per_paper] * num_papers\n",
    "\n",
    "    # Arcs from papers to reviewers (with correct offset)\n",
    "    for paper in range(1, num_papers + 1):\n",
    "        for reviewer in willing_reviewers[paper]:\n",
    "            start_nodes.append(paper)\n",
    "            end_nodes.append(reviewer + num_papers)  # Add offset here\n",
    "            capacities.append(1)\n",
    "\n",
    "    # Arcs from reviewers to sink\n",
    "    for reviewer in range(1, num_reviewers + 1):\n",
    "        start_nodes.append(reviewer + num_papers)\n",
    "        end_nodes.append(sink)\n",
    "        capacities.append(max_load)\n",
    "    return start_nodes, end_nodes, capacities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38b0db2",
   "metadata": {},
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61497532",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time_execution\n",
    "def max_flow_method(): \n",
    "    # Instantiate a SimpleMaxFlow solver.\n",
    "    smf = max_flow.SimpleMaxFlow()\n",
    "\n",
    "    # Read input data\n",
    "    num_papers, num_reviewers, reviews_per_paper, willing_reviewers = input_data()\n",
    "\n",
    "    #Minimum capactices of max_load\n",
    "    if (num_papers*reviews_per_paper) % num_reviewers == 0:\n",
    "        low=(num_papers*reviews_per_paper) // num_reviewers\n",
    "    else:\n",
    "        low=(num_papers*reviews_per_paper) // num_reviewers + 1\n",
    "    \n",
    "    willing_papers = reverse_dict(willing_reviewers)\n",
    "    willing_papers=dict(sorted(willing_papers.items(), key=lambda item: len(item[1])))\n",
    "    high= max(len(papers) for papers in willing_papers.values()) if willing_papers else 0\n",
    "        \n",
    "    #Dirichlet's theorem\n",
    "    max_load= low\n",
    "\n",
    "    while max_load<=high:        \n",
    "        start_nodes, end_nodes, capacities = pre_processing_data(num_papers,num_reviewers,reviews_per_paper ,willing_reviewers,max_load)\n",
    "        #   note: we could have used add_arc_with_capacity(start, end, capacity)\n",
    "        all_arcs = smf.add_arcs_with_capacity(start_nodes, end_nodes, capacities)\n",
    "\n",
    "        # Find the maximum flow between node 0 and node 4.\n",
    "        status = smf.solve(0, num_papers + num_reviewers + 1)\n",
    "\n",
    "        if (status == smf.OPTIMAL) and smf.optimal_flow()== num_papers * reviews_per_paper:\n",
    "            # Print the solution\n",
    "            \"\"\"print(num_papers)\n",
    "            solution_flows = smf.flows(all_arcs)\n",
    "            arc_indices = {arc: i for i, arc in enumerate(zip(start_nodes, end_nodes))}\n",
    "       \n",
    "            for paper in range(1, num_papers + 1):\n",
    "                print(reviews_per_paper, end=' ')\n",
    "                assigned_reviewers = []\n",
    "                \n",
    "                # Check all arcs from this paper to reviewers\n",
    "                for reviewer in willing_reviewers[paper]:\n",
    "                    arc = (paper, reviewer + num_papers)\n",
    "                    if arc in arc_indices:\n",
    "                        flow_index = arc_indices[arc]\n",
    "                        if solution_flows[flow_index] == 1:\n",
    "                            assigned_reviewers.append(reviewer)\n",
    "                \n",
    "                # Print assigned reviewers\n",
    "                for rev in assigned_reviewers[:reviews_per_paper]:  # Ensure we don't exceed required reviews\n",
    "                    print(rev, end=' ')\n",
    "                print()\"\"\"\n",
    "            print(max_load) \n",
    "            break\n",
    "        else:\n",
    "            max_load += 1\n",
    "\n",
    "       \n",
    "        \n",
    "max_flow_method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a2a691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_papers(num_papers, num_reviewers, reviews_per_paper, willing_reviewers):\n",
    "    load = [0] * (num_reviewers + 1)\n",
    "    sorted_dict = dict(sorted(willing_reviewers.items(), key=lambda item: len(item[1])))\n",
    "    selected_reviewers = {}\n",
    "    for paper,reviewers in sorted_dict.items():\n",
    "        #Sort the reviewers by their current load\n",
    "        reviewers.sort(key=lambda x: load[x])\n",
    "        # Select the first K reviewers\n",
    "        selected_reviewers[paper] = reviewers[:reviews_per_paper]\n",
    "        # Update the load of the selected reviewers\n",
    "        for reviewer in selected_reviewers[paper]:\n",
    "            load[reviewer] += 1\n",
    "    # Find the maximum load\n",
    "    max_load = max(load[1:])\n",
    "    return max_load, selected_reviewers\n",
    "@time_execution\n",
    "def greedy_method(): \n",
    "    # Read input data\n",
    "    num_papers, num_reviewers, reviews_per_paper, willing_reviewers = input_data()\n",
    "    \n",
    "    # Call the matching function\n",
    "    max_load, selected_reviewers = matching_papers(num_papers, num_reviewers, reviews_per_paper, willing_reviewers)\n",
    "    \n",
    "    # Print the result\n",
    "    \"\"\"print(num_papers)\n",
    "    for paper in range(1, num_papers + 1):\n",
    "        print(reviews_per_paper, end=' ')\n",
    "        for reviewer in selected_reviewers.get(paper, []):\n",
    "            print(reviewer, end=' ')\n",
    "        print()\"\"\"\n",
    "    print(max_load)\n",
    "    \n",
    "greedy_method() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e1ce781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_papers_2(num_papers, num_reviewers, reviews_per_paper, willing_reviewers):\n",
    "    load = {i: 0 for i in range(1, num_reviewers + 1)}  # Fixed: Start from 1 instead of 0\n",
    "    sorted_dict = dict(sorted(willing_reviewers.items(), key=lambda item: len(item[1])))\n",
    "    selected_reviewers = {}\n",
    "    for paper,reviewers in sorted_dict.items():\n",
    "        #Sort the reviewers by their current load\n",
    "        reviewers.sort(key=lambda x: load[x])\n",
    "        # Select the first K reviewers\n",
    "        selected_reviewers[paper] = reviewers[:reviews_per_paper]\n",
    "        # Update the load of the selected reviewers\n",
    "        for reviewer in selected_reviewers[paper]:\n",
    "            load[reviewer] += 1\n",
    "    # Find the maximum load\n",
    "    max_load = max(load.values())\n",
    "    return max_load, selected_reviewers, load\n",
    "\n",
    "def local_search(num_papers, num_reviewers, reviews_per_paper, willing_papers, assigned_papers, current_load, depth=0):\n",
    "    if depth > 100:  # Limit recursion depth\n",
    "        return assigned_papers, current_load\n",
    "    \n",
    "    changed = False\n",
    "    sorted_load = dict(sorted(current_load.items(), key=lambda item: item[1]))\n",
    "    #get the max load\n",
    "    reviewer_of_max_load = max(current_load, key=current_load.get)\n",
    "    max_load = current_load[reviewer_of_max_load]\n",
    "    \n",
    "    for candidate in sorted_load.keys():\n",
    "        if sorted_load[candidate] < max_load-1:\n",
    "            # Ensure both reviewers exist in the dictionaries\n",
    "            if candidate not in willing_papers:\n",
    "                willing_papers[candidate] = []\n",
    "            if reviewer_of_max_load not in assigned_papers:\n",
    "                continue\n",
    "                \n",
    "            available_papers = list(set(willing_papers.get(candidate, [])) & set(assigned_papers[reviewer_of_max_load]))\n",
    "            if len(available_papers) > 0:\n",
    "                random_paper = random.choice(available_papers)\n",
    "                assigned_papers[candidate].append(random_paper)\n",
    "                assigned_papers[reviewer_of_max_load].remove(random_paper)\n",
    "                # Update the load\n",
    "                current_load[candidate] += 1\n",
    "                current_load[reviewer_of_max_load] -= 1\n",
    "                changed=True\n",
    "                break\n",
    "                \n",
    "    if changed:\n",
    "        return local_search(num_papers, num_reviewers, reviews_per_paper, willing_papers, assigned_papers, current_load, depth+1)\n",
    "\n",
    "    return assigned_papers, current_load\n",
    "@time_execution\n",
    "def local_search_method():\n",
    "    num_papers, num_reviewers, reviews_per_paper, willing_reviewers = input_data()\n",
    "    willing_papers = reverse_dict(willing_reviewers)\n",
    "\n",
    "    \n",
    "    max_load, selected_reviewers, current_load = matching_papers_2(num_papers, num_reviewers, reviews_per_paper, willing_reviewers)\n",
    "    \n",
    "    # Calculate assigned papers for each reviewer\n",
    "    assigned_papers = reverse_dict(selected_reviewers)\n",
    "    \n",
    "    # Update willing papers by removing already assigned papers\n",
    "    reviewer_willing_papers = {}\n",
    "    for i in range(1, num_reviewers+1):\n",
    "        if i in willing_papers:\n",
    "            reviewer_willing_papers[i] = list(set(willing_papers[i]) - set(assigned_papers.get(i, [])))\n",
    "    \n",
    "    # Perform local search\n",
    "    optimized_assignments, final_load = local_search(num_papers, num_reviewers, reviews_per_paper, reviewer_willing_papers, assigned_papers, current_load)\n",
    "    selected_reviewers=reverse_dict(optimized_assignments)\n",
    "    \"\"\"print(num_papers)\n",
    "    for paper, reviewers in selected_reviewers.items():\n",
    "        print(f\"{reviews_per_paper} {' '.join(map(str, reviewers))}\")\"\"\"\n",
    "    print(f\"Max load: {max(final_load.values())}\")\n",
    "\n",
    "local_search_method()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
